{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Audio_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nulven/PrivacyML/blob/master/Audio_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoAZ1k8I8FI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5121ee-a39c-4c8f-d291-02490c046ac5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9FvGehOiy62",
        "outputId": "8035a079-6514-41a9-acd2-441a78541079"
      },
      "source": [
        "%cd '/content/drive/MyDrive/csail/mnist'"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/csail/mnist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pceNH6Z-Gs7T"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW16aOykGs7U"
      },
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import os\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efpZm5zmGs7U"
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mymSxY-JGs7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cfcc01-f76b-4987-a1a3-e917cc647dc6"
      },
      "source": [
        "import librosa\n",
        "audio_folder = '/content/drive/MyDrive/csail/mnist/audio_mnist'\n",
        "\n",
        "audio = listdir(audio_folder)\n",
        "# neg_audio = listdir(neg_audio_folder)\n",
        "\n",
        "len(audio)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPaVL-2vGs7W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "299b1fa2-100e-4e3c-c8d2-c0ab55f1d649"
      },
      "source": [
        "import IPython.display as ipd\n",
        "ipd.Audio(join(audio_folder,audio[7]))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VerUY9bqGs7W"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxZg7x44Gs7Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6132ebdc-d082-4d45-e8fd-b5a85264e873"
      },
      "source": [
        "#Audio Plots\n",
        "from tqdm import tqdm \n",
        "import time \n",
        "'''\n",
        "for aud in tqdm(audio):\n",
        "  x , sr = librosa.load(audio_folder+'/'+aud)\n",
        "  mfccs = librosa.feature.mfcc(x, sr=sr)\n",
        "  fig = plt.Figure()\n",
        "  canvas = FigureCanvas(fig)\n",
        "  ax = fig.add_subplot(111)\n",
        "  librosa.display.specshow(mfccs, sr=sr)\n",
        "  plt.margins(0,0)\n",
        "  plt.axis('off')\n",
        "  plt.savefig('/content/drive/MyDrive/csail/mnist/audio_plots/' + aud + '.png',bbox_inches='tight',pad_inches = 0)\n",
        "  # time.sleep(0.01)\n",
        "'''"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor aud in tqdm(audio):\\n  x , sr = librosa.load(audio_folder+'/'+aud)\\n  mfccs = librosa.feature.mfcc(x, sr=sr)\\n  fig = plt.Figure()\\n  canvas = FigureCanvas(fig)\\n  ax = fig.add_subplot(111)\\n  librosa.display.specshow(mfccs, sr=sr)\\n  plt.margins(0,0)\\n  plt.axis('off')\\n  plt.savefig('/content/drive/MyDrive/csail/mnist/audio_plots/' + aud + '.png',bbox_inches='tight',pad_inches = 0)\\n  # time.sleep(0.01)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ISmR4bGs7Y"
      },
      "source": [
        "#Dataset Path\n",
        "images = '/content/drive/MyDrive/csail/mnist/audio_plots'"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs2redjGGs7Z"
      },
      "source": [
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "ds_trans = transforms.Compose([transforms.Resize(224),\n",
        "                               transforms.ToTensor(),\n",
        "                               normalize])"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMZUJl7BGs7Z"
      },
      "source": [
        "files = os.listdir('/content/drive/MyDrive/csail/mnist/audio_mnist')\n",
        "digits = [int(file[0]) for file in files]\n",
        "names = [file.split('_')[1] for file in files]\n",
        "d = {'fname': files, 'label': digits, 'name': names}\n",
        "labels = pd.DataFrame(data=d)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEeKX0SfGs7a"
      },
      "source": [
        "#Viewing Image\n",
        "from IPython.display import Image\n",
        "# Image(images+'pos-0422-096-cough-m-31-8.mp3.png')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lkWN-DEGs7b"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class HeartbeatDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.annotations = annotation_file\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_id = self.annotations.iloc[index, 0]\n",
        "        img = Image.open(os.path.join(self.root_dir, img_id+'.png')).convert(\"RGB\")\n",
        "        y_label = torch.tensor(float(self.annotations.iloc[index, 1])).type(torch.LongTensor)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return (img, y_label)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "ds_trans = transforms.Compose([transforms.Resize(224),\n",
        "                               transforms.CenterCrop(224),\n",
        "                               transforms.ToTensor(),\n",
        "                               normalize])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjyMOoZQGs7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9336762-5685-4195-8e32-365c58152637"
      },
      "source": [
        "dataset = HeartbeatDataset(\"/content/drive/MyDrive/csail/mnist/audio_plots\",labels,transform=ds_trans)\n",
        "\n",
        "train_set, validation_set = torch.utils.data.random_split(dataset,[2000, 1000])\n",
        "\n",
        "train_dl = DataLoader(dataset=train_set, shuffle=True, batch_size=4,num_workers=4)\n",
        "valid_dl = DataLoader(dataset=validation_set, shuffle=True, batch_size=4,num_workers=4)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJK3uss4Gs7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504b05be-109c-44b7-cce0-6841c839e1f2"
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "inputs, labels = next(iter(train_dl))\n",
        "if use_gpu:\n",
        "    resnet = resnet.cuda()\n",
        "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())   \n",
        "else:\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "outputs = resnet(inputs)\n",
        "outputs.size()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjNNQEMwGs7e"
      },
      "source": [
        "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "    dataset_sizes = {'train': len(dataloders['train'].dataset), \n",
        "                     'valid': len(dataloders['valid'].dataset)}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloders[phase]:\n",
        "                if use_gpu:\n",
        "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "                # print(\"F1 Score = {}, Precision = {}, Recall = {}\".format(f1(labels,preds),precision(labels,preds),recall(labels,preds)))\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                running_loss += loss.data\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            if phase == 'train':\n",
        "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                train_epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "            else:\n",
        "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "                \n",
        "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
        "                best_acc = valid_epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n",
        "              'valid loss: {:.4f} acc: {:.4f}'.format(\n",
        "                epoch, num_epochs - 1,\n",
        "                train_epoch_loss, train_epoch_acc, \n",
        "                valid_epoch_loss, valid_epoch_acc))\n",
        "            \n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yie7UU4Gs7f"
      },
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "# freeze all model parameters\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# new final layer with 2 classes\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = torch.nn.Linear(num_ftrs, 10)\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "if use_gpu:\n",
        "    resnet = resnet.cuda()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(resnet.fc.parameters(), lr=0.05, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "dloaders = {'train':train_dl, 'valid':valid_dl}"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZRXQH1lGs7g"
      },
      "source": [
        "#start_time = time.time()\n",
        "#model = train_model(dloaders, resnet, criterion, optimizer, exp_lr_scheduler, num_epochs=20)\n",
        "#print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue0p6jVEGs7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fba1e01-b150-4f64-b0e4-d00444099042"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.7/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (5.3.1)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.8.7)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.0+cu101)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.7.0)\n",
            "Requirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.7.4.post0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.27.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (5.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko6pabx8Gs7h"
      },
      "source": [
        "from pytorch_lightning.metrics.classification import Precision, Recall, F1\n",
        "\n",
        "precision = Precision(num_classes = 10)\n",
        "recall = Recall()\n",
        "f1 = F1(num_classes = 10)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qz8NxpnGs7h"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtvJUjMWi748"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
        "import torchvision\n",
        "import torchvision.transforms as tt\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import MNIST, CIFAR10, ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import random_split, DataLoader, Subset\n",
        "from torch.nn.utils import vector_to_parameters, parameters_to_vector\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-hkRbC63W2l"
      },
      "source": [
        "batch_size=100"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O9WCisK13lML",
        "outputId": "da46cfd7-a724-44bf-9db7-164e7fd9762c"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "device = 'cpu'\n",
        "device"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3zMajnmo2QD"
      },
      "source": [
        "class MnistNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(1, 10, 5),\n",
        "                                   nn.MaxPool2d(2),\n",
        "                                   nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(10, 20, kernel_size=5),\n",
        "                                   nn.Dropout2d(),\n",
        "                                   nn.MaxPool2d(2),\n",
        "                                   nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(nn.Flatten(),\n",
        "                                 nn.Linear(320, 50),\n",
        "                                 nn.Dropout(),\n",
        "                                 nn.ReLU())\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heolWQ0tc40Q"
      },
      "source": [
        "def train(model, train_dl, optimizer, criterion):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    batch_loss, batch_acc = [], []\n",
        "    for images, labels in train_dl:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_loss.append(loss.detach().cpu())\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        batch_acc.append(accuracy_score(labels.cpu(), pred.cpu()))\n",
        "    model.cpu()\n",
        "    return sum(batch_loss)/len(batch_loss), sum(batch_acc)/len(batch_acc)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icWIUYM_c0U4"
      },
      "source": [
        "def test(model, test_dl, criterion):      \n",
        "    with torch.no_grad():\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        batch_loss, batch_acc = [], []\n",
        "        for images, labels in test_dl:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            batch_loss.append(loss.cpu())\n",
        "            pred = torch.argmax(logits, dim=1)\n",
        "            batch_acc.append(accuracy_score(labels.cpu(), pred.cpu()))\n",
        "        model.cpu()\n",
        "        return sum(batch_loss)/len(batch_loss), sum(batch_acc)/len(batch_acc)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-nbZwh6csSd"
      },
      "source": [
        "def fit(epochs, model, optimizer,criterion, train_dl, test_dl):\n",
        "    train_loss, train_acc, test_loss, test_acc = [], [], [], []\n",
        "    for epoch in range(1,epochs+1):\n",
        "        trainl, traina = train(model, train_dl, optimizer, criterion)\n",
        "        testl , testa = test(model, test_dl, criterion)\n",
        "        train_loss.append(trainl)\n",
        "        train_acc.append(traina)\n",
        "        test_loss.append(testl)\n",
        "        test_acc.append(testa)\n",
        "        print(f'Epoch {epoch} - train_loss : {trainl :.4f}, train_acc : {traina:.4f}, test_loss : {testl:.4f}, test_acc : {testa:0.4f}')\n",
        "\n",
        "    history = {'train_loss' : train_loss,\n",
        "               'train_acc' : train_acc,\n",
        "               'test_loss' : test_loss,\n",
        "               'test_acc' : test_acc}\n",
        "    return history"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho_D4n9BpgJI"
      },
      "source": [
        "def plot(epochs, title, history):\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "    t = f.suptitle(title, fontsize=24)\n",
        "    f.patch.set_facecolor('white')\n",
        "    f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "    epoch_list = list(range(1,epochs+1))\n",
        "\n",
        "    ax1.plot(epoch_list, history['train_acc'], label='Train Accuracy')\n",
        "    ax1.plot(epoch_list, history['test_acc'], label='Test Accuracy')\n",
        "    ax1.set_ylabel('Accuracy Value')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_title('Accuracy', fontsize = 18)\n",
        "    ax1.grid(True)\n",
        "    l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "    ax2.plot(epoch_list, history['train_loss'], label='Train Loss')\n",
        "    ax2.plot(epoch_list, history['test_loss'], label='Test Loss')\n",
        "    ax2.set_ylabel('Loss Value')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_title('Loss', fontsize = 18)\n",
        "    ax2.grid(True)\n",
        "    l2 = ax2.legend(loc=\"best\")\n",
        "    return f"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUz3R7KQY59V"
      },
      "source": [
        "def save(history, model, figure, name):\n",
        "    with open(name + '.pickle', 'wb') as handle:\n",
        "        pickle.dump(history, handle)\n",
        "    torch.save(model, name + '.pth')\n",
        "    figure.savefig(name + '.png')"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rIaRHnz-j40"
      },
      "source": [
        "def make_iid_dls(train_ds, n):\n",
        "    size = len(train_ds)//n\n",
        "    last_size = size + len(train_ds)%n\n",
        "    client_ds = random_split(train_ds, [size]*(n-1) + [last_size])\n",
        "    client_dls = [DataLoader(ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)for ds in client_ds]\n",
        "    return client_dls"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZOAxlY_T7y"
      },
      "source": [
        "def make_noniid_dls(train_ds, n):\n",
        "    num_shards, num_imgs = 2*n, len(train_ds)//(2*n)\n",
        "    idx_shard = [i for i in range(num_shards)]\n",
        "    dict_clients = {i: np.array([]) for i in range(n)}\n",
        "    idxs = np.arange(num_shards*num_imgs)\n",
        "    labels = train_ds.targets\n",
        "\n",
        "    # sort labels\n",
        "    idxs_labels = np.vstack((idxs, labels[:len(idxs)]))\n",
        "    idxs_labels = idxs_labels[:,idxs_labels[1,:].argsort()]\n",
        "    idxs = idxs_labels[0,:]\n",
        "\n",
        "    # divide and assign\n",
        "    for i in range(n):\n",
        "        rand_set = set(np.random.choice(idx_shard, 2, replace=False))\n",
        "        idx_shard = list(set(idx_shard) - rand_set)\n",
        "        for rand in rand_set:\n",
        "            dict_clients[i] = np.concatenate((dict_clients[i], idxs[rand*num_imgs:(rand+1)*num_imgs]), axis=0)\n",
        "\n",
        "    client_dls = []\n",
        "    for i in range(n):\n",
        "        ds = Subset(train_ds, torch.LongTensor(dict_clients[i]))\n",
        "        client_dls.append(DataLoader(ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True))\n",
        "    return client_dls"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFyPteStTiuH"
      },
      "source": [
        "def make_iid_dls_with_speakers(train_ds, n):\n",
        "    size = len(train_ds)//n\n",
        "    last_size = size + len(train_ds)%n\n",
        "    train_ds = train_ds.reset_index(drop=True)\n",
        "    idxs = train_ds.index\n",
        "    client_idxs = random_split(list(idxs), [size]*(n-1) + [last_size])\n",
        "    print(client_idxs[0])\n",
        "    client_ds = [train_ds.iloc[list(idxs)] for idxs in client_idxs]\n",
        "    client_ds = [HeartbeatDataset(\"/content/drive/MyDrive/csail/mnist/audio_plots\",ds,transform=ds_trans) for ds in client_ds]\n",
        "    client_dls = [DataLoader(ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)for ds in client_ds]\n",
        "    return client_dls"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_xNxBQ8I8Uj"
      },
      "source": [
        "def make_noniid_dls_with_speakers(train_ds, n=6):\n",
        "    client_dls = []\n",
        "    for name in set(train_ds.name):\n",
        "      subset = train_ds[train_ds.name == name]\n",
        "      subset = subset.reset_index(drop=True)\n",
        "      ds = HeartbeatDataset(\"/content/drive/MyDrive/csail/mnist/audio_plots\",subset,transform=ds_trans)\n",
        "      client_dls.append(DataLoader(ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True))\n",
        "   \n",
        "    return client_dls"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHjKZYtTB1to",
        "outputId": "677fb44e-a386-4c4e-976c-dbbdd682872e"
      },
      "source": [
        "dataset = HeartbeatDataset(\"/content/drive/MyDrive/csail/mnist/audio_plots\",labels,transform=ds_trans)\n",
        "\n",
        "train_idxs = []\n",
        "validation_idxs = []\n",
        "for name in set(labels.name):\n",
        "  for digit in range(10):\n",
        "    idxs = labels[labels.name == name]\n",
        "    idxs = idxs[idxs.label == digit].index\n",
        "    train_idxs1, validation_idxs1 = torch.utils.data.random_split(list(idxs), [30, 20])\n",
        "    train_idxs.extend(list(train_idxs1))\n",
        "    validation_idxs.extend(list(validation_idxs1))\n",
        "train_set, validation_set = torch.utils.data.Subset(dataset, train_idxs), torch.utils.data.Subset(dataset, validation_idxs)\n",
        "train_ds, validation_ds = labels.iloc[train_idxs], labels.iloc[validation_idxs]\n",
        "\n",
        "train_dl = DataLoader(dataset=train_set, shuffle=True, batch_size=4,num_workers=4)\n",
        "validation_dl = DataLoader(dataset=validation_set, shuffle=True, batch_size=4,num_workers=4)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVMoOyEA_b2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3cac8f-b4c3-4b7b-8aa8-fc127ee01202"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "n = 6\n",
        "iid_dls = make_iid_dls_with_speakers(train_ds, n)\n",
        "noniid_dls = make_noniid_dls_with_speakers(train_ds, n)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataset.Subset object at 0x7f5a87700b50>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyv32fYdBMrc"
      },
      "source": [
        "def make_clients(n):\n",
        "    models = [resnet for _ in range(n)]\n",
        "    optimizers = [SGD(model.parameters(), lr=1e-2, momentum=0.9) for model in models]\n",
        "    return models, optimizers"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33x_fEfYB25z"
      },
      "source": [
        "def train_clients(client_models, client_optimizers, server_model, criterion, client_dls):\n",
        "    client_loss, client_acc = [], []\n",
        "    for model, optimizer, train_dl in zip(client_models, client_optimizers, client_dls):\n",
        "        model.load_state_dict(server_model.state_dict())\n",
        "        closs, cacc = train(model, train_dl, optimizer, criterion)\n",
        "        client_loss.append(closs)\n",
        "        client_acc.append(cacc)\n",
        "    return sum(client_loss)/len(client_loss), sum(client_acc)/len(client_acc)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIL89s4ACF20"
      },
      "source": [
        "def compute_gradient(client_models, server_model, r, compression,sparsity, warmup, epoch):\n",
        "    n = len(client_models)\n",
        "    server_dict = server_model.state_dict()\n",
        "    grad_dict = {k : torch.zeros_like(v) for k, v in server_dict.items()}\n",
        "    if compression is None:\n",
        "        for model in client_models:\n",
        "            client_dict =  model.state_dict()\n",
        "            for name in client_dict:\n",
        "                grad_dict[name] += client_dict[name]\n",
        "        grad_dict = {k : v/n-server_dict[k] for k,v in grad_dict.items()}\n",
        "    else:\n",
        "        if epoch <= warmup:\n",
        "            scale = (sparsity/(1-1/n))**(1/warmup) if compression == 'rTopk' else (sparsity/0.00001)**(1/warmup)\n",
        "            sparsity /= scale**(warmup-epoch+1)\n",
        "        grad_vector = nn.utils.parameters_to_vector(grad_dict.values())\n",
        "        count_vector = copy.deepcopy(grad_vector)\n",
        "        for i, model in enumerate(client_models):\n",
        "            client_dict =  model.state_dict()\n",
        "            residual_dict = r[i]\n",
        "            g = {k : client_dict[k] - server_dict[k] + residual_dict[k] for k in client_dict}\n",
        "            g_vector = nn.utils.parameters_to_vector(g.values())\n",
        "            if compression == \"rTopk\":\n",
        "                _, rtop_idx = torch.topk(g_vector.abs(), int((1-sparsity)* len(g_vector))*n, sorted = False)\n",
        "                topk_idx = np.random.choice(rtop_idx, len(rtop_idx)//n, replace = False)\n",
        "            else:\n",
        "                _, topk_idx = torch.topk(g_vector.abs(), int((1-sparsity)* len(g_vector)), sorted = False)\n",
        "            residual_vector = copy.deepcopy(g_vector)\n",
        "            residual_vector[topk_idx] = 0\n",
        "            nn.utils.vector_to_parameters(residual_vector, residual_dict.values())\n",
        "            grad_vector[topk_idx] += g_vector[topk_idx]\n",
        "            count_vector[topk_idx] += 1\n",
        "        count_vector[count_vector == 0] = 1\n",
        "        grad_vector /= count_vector\n",
        "        nn.utils.vector_to_parameters(grad_vector, grad_dict.values())\n",
        "    return grad_dict"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aIvinj6Cd5V"
      },
      "source": [
        "def train_server(model, opt, lr, g, m, v, beta1, beta2, epsilon, epoch, demon, total_epochs):\n",
        "    s_dict = model.state_dict()\n",
        "    if opt == 'sgd':\n",
        "        new_s_dict = {k : s_dict[k] + lr * g[k] for k in s_dict}\n",
        "    else:\n",
        "        if demon:\n",
        "            p = (1-epoch/total_epochs) \n",
        "            beta1 *= p/(1-beta1 + beta1*p)\n",
        "            m = {k : beta1*m[k] + g[k] for k in g}\n",
        "        else:\n",
        "            m = {k : beta1*m[k] + (1-beta1)*g[k] for k in g}\n",
        "        if opt == 'adagrad':\n",
        "            v =  {k : v[k] + g[k]**2 for k in v}\n",
        "        if opt == 'yogi':\n",
        "            v = {k : v[k] - (1-beta2)*torch.sign(v[k] - g[k]**2)*(g[k]**2) for k in v}\n",
        "        if opt == 'adam':\n",
        "            v = {k : beta2*v[k] + (1-beta2)*(g[k]**2) for k in v}\n",
        "        lr *= ((1-beta2**epoch)**0.5)/(1-beta1**epoch)\n",
        "        new_s_dict = {k : s_dict[k] + lr * m[k]/(v[k]**0.5 + epsilon) for k in s_dict}\n",
        "    model.load_state_dict(new_s_dict)\n",
        "    return m, v"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuVLArwLCgSw"
      },
      "source": [
        "def fit_federated(epochs, client_models, client_optimizers, client_dls, \n",
        "                  server_model, server_opt, server_lr, test_dl, criterion,\n",
        "                  beta1 = 0, beta2 = 0, epsilon = 1e-8, demon = False, compression = None, sparsity = 0, warmup = 5):\n",
        "    s_dict = server_model.state_dict()\n",
        "    m = {k : torch.zeros_like(v) for k, v in s_dict.items()}\n",
        "    v = copy.deepcopy(m)\n",
        "    r = [copy.deepcopy(m) for _ in range(len(client_models))]\n",
        "    train_loss, train_acc, test_loss, test_acc = [], [], [], []\n",
        "    for epoch in range(1,epochs+1):\n",
        "        trainl, traina = train_clients(client_models, client_optimizers, server_model, criterion, client_dls)\n",
        "        g = compute_gradient(client_models, server_model, r, compression, sparsity, warmup, epoch)\n",
        "        m, v = train_server(server_model, server_opt, server_lr, g, m, v, beta1, beta2, epsilon, epoch, demon, epochs)\n",
        "        testl , testa = test(server_model, test_dl, criterion)\n",
        "        train_loss.append(trainl)\n",
        "        train_acc.append(traina)\n",
        "        test_loss.append(testl)\n",
        "        test_acc.append(testa)\n",
        "        print(f'Epoch {epoch} - train_loss : {trainl :.4f}, train_acc : {traina:.4f}, test_loss : {testl:.4f}, test_acc : {testa:0.4f}')\n",
        "\n",
        "    history = {'train_loss' : train_loss,\n",
        "               'train_acc' : train_acc,\n",
        "               'test_loss' : test_loss,\n",
        "               'test_acc' : test_acc}\n",
        "    return history"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgbEEtAgPL4S"
      },
      "source": [
        "epochs = 250\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfXwKnFYPdIg"
      },
      "source": [
        "client_models, client_optimizers = make_clients(n)\n",
        "server_model = resnet\n",
        "server_opt = 'sgd'\n",
        "server_lr = 1"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtU9zcTtPZcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd366478-786b-40eb-a73c-8b024883eb2e"
      },
      "source": [
        "iid_sgd_history = fit_federated(epochs, client_models, client_optimizers, iid_dls, \n",
        "                                server_model, server_opt, server_lr, validation_dl, criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - train_loss : 2.2689, train_acc : 0.1589, test_loss : 2.2836, test_acc : 0.1158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deI_-bt5P0KB"
      },
      "source": [
        "f = plot(epochs, \"IID SGD Performace\", iid_sgd_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHio86ABP5w9"
      },
      "source": [
        "save(iid_sgd_history, server_model, f, \"IID_SGD\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AQYYRyyP6bx"
      },
      "source": [
        "client_models, client_optimizers = make_clients(n)\n",
        "server_model = MnistNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CilK7y12QE6C"
      },
      "source": [
        "noniid_sgd_history = fit_federated(epochs, client_models, client_optimizers, noniid_dls, \n",
        "                                server_model, server_opt, server_lr, test_dl, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwb1EbcuQJuP"
      },
      "source": [
        "f = plot(epochs, \"NonIID-SGD Performance\", noniid_sgd_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8XQ1xL9QKJB"
      },
      "source": [
        "save(noniid_sgd_history, server_model, f, \"NonIID_SGD\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrUayrh2QTMC"
      },
      "source": [
        "client_models, client_optimizers = make_clients(n)\n",
        "server_model = MnistNet()\n",
        "server_opt = 'adam'\n",
        "server_lr = 0.003\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "epsilon = 1e-8\n",
        "demon = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uUF0W4RsL2g"
      },
      "source": [
        "noniid_demon_adam_history = fit_federated(epochs, client_models, client_optimizers, noniid_dls, \n",
        "                  server_model, server_opt, server_lr, test_dl, criterion,\n",
        "                  beta1, beta2, epsilon, demon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC6hEGIXsxcY"
      },
      "source": [
        "f = plot(epochs, \"NonIID Demon Adam Performace\", noniid_demon_adam_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRIihS96s-Zf"
      },
      "source": [
        "save(noniid_demon_adam_history, server_model, f, \"NonIID_Demon_Adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVPMhb_rtFfT"
      },
      "source": [
        "client_models, client_optimizers = make_clients(n)\n",
        "server_model = MnistNet()\n",
        "compression = 'rTopk'\n",
        "server_lr = 0.001\n",
        "sparsity = 0.99\n",
        "warmup = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyHYvLc5vIkK"
      },
      "source": [
        "noniid_demon_adam_rtopk_history = fit_federated(epochs, client_models, client_optimizers, noniid_dls, \n",
        "                  server_model, server_opt, server_lr, test_dl, criterion,\n",
        "                  beta1, beta2 , epsilon , demon , compression , sparsity , warmup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEyMYtcWuy-Q"
      },
      "source": [
        "f = plot(epochs, \"NonIID Demon Adam with 99% rTopk Compression Performace\", noniid_demon_adam_rtopk_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDdxYY1nvLXr"
      },
      "source": [
        "save(noniid_demon_adam_rtopk_history, server_model, f, \"NonIID_Demon_Adam_rTopk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EBhFYNpvfA6"
      },
      "source": [
        "client_models, client_optimizers = make_clients(n)\n",
        "server_model = MnistNet()\n",
        "server_opt = 'sgd'\n",
        "server_lr = 0.1\n",
        "compression = 'rTopk'\n",
        "sparsity = 0.99\n",
        "warmup = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVooxoE-5reQ"
      },
      "source": [
        "noniid_sgd_rtopk_history = fit_federated(epochs, client_models, client_optimizers, noniid_dls, \n",
        "                  server_model, server_opt, server_lr, test_dl, criterion,\n",
        "                  compression = compression , sparsity = sparsity , warmup = warmup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuYC0OvUTG69"
      },
      "source": [
        "f = plot(epochs, \"NonIID SGD with 99% rTopk Compression Performace\", noniid_sgd_rtopk_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ei20Tn5s_L"
      },
      "source": [
        "save(noniid_sgd_rtopk_history, server_model, f, \"NonIID_SGD_rTopk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_bqXw-vTMaZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}